\begin{table}[h]
	\centering
	{\scriptsize
		\renewcommand{\arraystretch}{1.5}
		\begin{tabular}{|>{\raggedright\arraybackslash}p{3.2cm}|>{\raggedright\arraybackslash}p{3.5cm}|>{\raggedright\arraybackslash}p{6cm}|}
			\hline
			\textbf{Архитектура} & \textbf{Подходит для} & \textbf{Особенности} \\
			\hline
			Перцептроны (FFNN) & Простые задачи классификации и регрессии & Простая структура, информация передается напрямую от входа к выходу \\
			\hline
			Рекуррентные сети (RNN) & Обработка последовательностей, текст, речь & Могут обрабатывать данные последовательно, сохраняя информацию о предыдущих входах \\
			\hline
			LSTM & Сложные последовательности, длинные тексты & Используются ворота для контроля потока информации, что помогает сохранять важные данные на длинных интервалах \\
			\hline
			GRU & Подобные LSTM задачи, но требуют меньше ресурсов & Упрощенная версия LSTM с меньшим количеством ворот, балансируют производительность и выразительность \\
			\hline
			Сверточные сети (CNN) & Распознавание изображений и видео & Используют свертки для эффективной работы с изображениями, улавливают пространственные иерархии \\
			\hline
			Генеративно-
			состязательные сети (GAN) & Генерация реалистичных изображений & Состоят из двух сетей (генератора и дискриминатора), которые соревнуются, улучшая друг друга \\
			\hline
			Автоэнкодеры (AE, VAE) & Сжатие данных, генерация данных & Обучаются сжимать входные данные в более мелкую форму и восстанавливать их \\
			\hline
			Капсульные сети (CapsNet) & Задачи, где важны пространственные отношения & Сети, использующие группы нейронов для сохранения информации о позиции и ориентации объектов \\
			\hline
			Трансформеры и сети внимания & Обработка естественного языка & Используют механизмы внимания для динамической фокусировки на разных частях данных \\
			\hline
		\end{tabular}
	}
	\caption{Обзор архитектур нейронных сетей и их применений.}
	\label{tab:ArchitecturesTable}
\end{table}