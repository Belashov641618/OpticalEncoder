{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e44e04-34eb-4af8-af8e-dec7c6bffdee",
   "metadata": {},
   "source": [
    "# Настройка среды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235392f8-3377-470d-b351-c339e4449161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740d57fa-5d4d-42e6-8079-24ad3177f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from belashovplot import TiledPlot\n",
    "from utilities import *\n",
    "from utilities.filters import Gaussian, Window\n",
    "from elements.abstracts import AbstractModulator\n",
    "from elements.modulators import Lens, PhaseModulator, AmplitudeModulator\n",
    "from elements.propagators import FurrierPropagation, ConvolutionalPropagation\n",
    "from elements.composition import CompositeModel, HybridModel\n",
    "from elements.wrappers import CudaMemoryChunker, Incoherent\n",
    "from elements.detectors import ClassificationDetectors, MatrixDetectors\n",
    "from elements.simple import AdjustSize\n",
    "from parameters import FigureWidthHeight, FontLibrary\n",
    "from tqdm import tqdm\n",
    "from math import sin, sqrt\n",
    "import torch\n",
    "from torch.profiler import profile\n",
    "import numpy\n",
    "import timm\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "from utilities.training import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b24713e-0f35-4248-ae84-2bee8ec84853",
   "metadata": {},
   "outputs": [],
   "source": [
    "FontLibrary.Fonts.PlotTitle.FontSize = 16\n",
    "\n",
    "FontLibrary.Fonts.DescriptionLeft.FontSize = 12\n",
    "FontLibrary.Fonts.DescriptionLeft.FontWeight = 'bold'\n",
    "FontLibrary.Fonts.DescriptionLeft.FontStyle = 'italic'\n",
    "\n",
    "FontLibrary.Fonts.DescriptionBottom.FontSize = 10\n",
    "FontLibrary.Fonts.DescriptionBottom.FontWeight = 'bold'\n",
    "FontLibrary.Fonts.DescriptionBottom.FontStyle = 'italic'\n",
    "\n",
    "FontLibrary.Fonts.DescriptionTop.FontSize = 10\n",
    "FontLibrary.Fonts.DescriptionTop.FontWeight = 'bold'\n",
    "FontLibrary.Fonts.DescriptionTop.FontStyle = 'italic'\n",
    "\n",
    "FontLibrary.Fonts.ColumnDescriptionTop.FontSize = 9\n",
    "FontLibrary.Fonts.ColumnDescriptionBottom.FontSize = 9\n",
    "FontLibrary.Fonts.RowDescriptionLeft.FontSize = 9\n",
    "FontLibrary.Fonts.RowDescriptionRight.FontSize = 9\n",
    "FontLibrary.Fonts.AxisX.FontSize = 8\n",
    "FontLibrary.Fonts.AxisY.FontSize = 8\n",
    "FigureWidthHeight = (6.69291, 10.1181-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "411922e2-7591-4d80-ab0a-59da2a51cfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемый девайс: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(7)\n",
    "print('Используемый девайс:', torch.cuda.get_device_name(device) if torch.cuda.is_available() else 'ЦП')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bf1309-b5fe-4a6e-a91a-8f10de680e0f",
   "metadata": {},
   "source": [
    "# Определение параметров модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a489ef8-0552-4fb0-abae-4c3a17e95c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(classes:int=10):\n",
    "    return timm.create_model('resnet18', pretrained=False, in_chans=1, num_classes=classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca47c0d2-3246-4672-b561-554bc5176cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(cross_entropy_to_mse_proportion:float=1.0):\n",
    "    def loss_function(outputs, targets):\n",
    "        CELoss = torch.nn.functional.cross_entropy(outputs, targets)\n",
    "        MSELoss = torch.nn.functional.mse_loss(torch.nn.functional.softmax(outputs, dim=1), torch.nn.functional.one_hot(targets, num_classes=10).float())\n",
    "        loss = cross_entropy_to_mse_proportion*CELoss + (1.0-cross_entropy_to_mse_proportion)*MSELoss\n",
    "        return loss\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9384ee63-2c6c-40ba-bb58-d1a944eafda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длинна волны:                             500.0 нм\n",
      "Количество вычислительных пикселей:       400\n",
      "Количество пикселей маски:                200\n",
      "Размер оптических элементов:              6.0 мм\n",
      "Размер пикселя маски:                     30.0 мкм\n",
      "Расстояние между слоями:                  50.0 мм\n",
      "Временная когерентность:                  10.0 нс\n",
      "Время релаксации:                         1.0 мкc\n",
      "Пространственная когерентность:           100.0 мкм\n",
      "Количество усреднений:                    10\n",
      "Размер детекторов:                        100.0 мкм\n",
      "Количество детекторов:                    24 на 24\n",
      "Пропорция CE к MSE лосс:                  0.609798\n",
      "Размер батча:                             32\n",
      "Тип оптимизатора:                         Adam\n"
     ]
    }
   ],
   "source": [
    "# Предпочтительные параметры\n",
    "size = 30.0E-6\n",
    "near_N = 400 #2004 #1336\n",
    "near_length = 6.0E-3\n",
    "wavelength = 500.0E-9\n",
    "detectors_amount = 24\n",
    "masks_amount = 10\n",
    "distance = 0.05\n",
    "\n",
    "# Параметры обучения\n",
    "batch_size = 32\n",
    "learning_rate = 0.009854\n",
    "loss_function_proportion = 0.609798\n",
    "optimizer_type_name = 'Adam'\n",
    "optimizer_types_list = {'Adam':torch.optim.Adam, 'SGD':torch.optim.SGD, 'RMSprop':torch.optim.RMSprop, 'Adagrad':torch.optim.Adagrad}\n",
    "\n",
    "# Параметры когерентности\n",
    "spatial_coherence = 100.0E-6\n",
    "time_coherence = 10.0E-9\n",
    "time_relaxation = 1.0E-6\n",
    "mean_samples = 10\n",
    "\n",
    "# Вычисляемые параметры\n",
    "pixels = upper_integer(near_length/size)\n",
    "length = pixels * size\n",
    "cppp = int(near_N * size / length)\n",
    "N = upper_integer(length*cppp / size) \n",
    "detector_size = length / 60\n",
    "\n",
    "print(f\"Длинна волны:                             {engineering(wavelength, 'м')}\")\n",
    "print(f\"Количество вычислительных пикселей:       {N}\")\n",
    "print(f\"Количество пикселей маски:                {pixels}\")\n",
    "print(f\"Размер оптических элементов:              {engineering(length, 'м')}\")\n",
    "print(f\"Размер пикселя маски:                     {engineering(length/pixels, 'м')}\")\n",
    "print(f\"Расстояние между слоями:                  {engineering(distance, 'м')}\")\n",
    "\n",
    "print(f\"Временная когерентность:                  {engineering(time_coherence, 'с')}\")\n",
    "print(f\"Время релаксации:                         {engineering(time_relaxation, 'c')}\")\n",
    "print(f\"Пространственная когерентность:           {engineering(spatial_coherence, 'м')}\")\n",
    "print(f\"Количество усреднений:                    {mean_samples}\")\n",
    "\n",
    "print(f\"Размер детекторов:                        {engineering(detector_size, 'м')}\")\n",
    "print(f\"Количество детекторов:                    {detectors_amount} на {detectors_amount}\")\n",
    "\n",
    "print(f\"Пропорция CE к MSE лосс:                  {loss_function_proportion}\")\n",
    "print(f\"Размер батча:                             {batch_size}\")\n",
    "print(f\"Тип оптимизатора:                         {optimizer_type_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b45035d-e791-4e7f-b2b4-c5549771785b",
   "metadata": {},
   "source": [
    "# Инициализация моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "892c9f95-42c7-4d94-9db5-cf7fa54199f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модуль некогерентности\n",
    "incoherent = Incoherent(spatial_coherence, time_coherence, time_relaxation, mean_samples, N, length)\n",
    "incoherent_encoder, incoherent_decoder = incoherent.pair()\n",
    "incoherent_encoder, incoherent_decoder = incoherent_encoder.to(device), incoherent_decoder.to(device)\n",
    "\n",
    "# Модули детекторов\n",
    "spectral_filter = Window(centers=wavelength, sizes=300.0E-9)\n",
    "detectors_filter = Gaussian((detector_size, detector_size), (0,0))\n",
    "detectors_incoherent = MatrixDetectors(N, length, wavelength, detectors_amount, detectors_filter, spectral_filter).to(device)\n",
    "detectors_coherent = deepcopy(detectors_incoherent)\n",
    "\n",
    "# Электронные модели\n",
    "electronic_incoherent = resnet18()\n",
    "electronic_coherent = deepcopy(electronic_incoherent)\n",
    "\n",
    "# Оптические модели\n",
    "adjuster = AdjustSize(N, N)\n",
    "propagation = FurrierPropagation(N, length, wavelength, 1.0, 0.0, distance, 0.4)\n",
    "phase_modulators = [PhaseModulator(N, length, pixels) for i in range(masks_amount)]\n",
    "amplitude_modulators = [AmplitudeModulator(N, length, pixels) for i in range(masks_amount)]\n",
    "elements = [phase_modulators[0], amplitude_modulators[0]]\n",
    "for phase_modulator, amplitude_modulator in zip(phase_modulators[1:], amplitude_modulators[1:]):\n",
    "    elements.append(propagation)\n",
    "    elements.append(phase_modulator)\n",
    "    elements.append(amplitude_modulator)\n",
    "elements.append(propagation)\n",
    "optical_incoherent = CompositeModel(adjuster, incoherent_encoder, *deepcopy(elements), incoherent_decoder).to(device)\n",
    "\n",
    "# Гибридные модели\n",
    "hybrid_model_incoherent = HybridModel(optical_incoherent, detectors_incoherent, electronic_incoherent).to(device)\n",
    "\n",
    "# Распределённые модели\n",
    "model_incoherent = hybrid_model_incoherent\n",
    "\n",
    "# Набор данных\n",
    "dataset = Dataset('CIFAR10', batch_size, None, None, torch.complex64, threads=1, preload=10)\n",
    "dataset.load.train()\n",
    "dataset.load.test()\n",
    "\n",
    "# Тип оптимизатора и лосс-функция\n",
    "loss_function = combined_loss(loss_function_proportion)\n",
    "optimizer_type = optimizer_types_list[optimizer_type_name]\n",
    "optimizer = optimizer_type(model_incoherent.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31f0b47-892d-4ff3-bf1a-49a31790ec49",
   "metadata": {},
   "source": [
    "# Тренировка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "052053e7-35a1-454b-8b16-14a9cc71c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterationBreaker:\n",
    "    def __init__(self, loader:torch.utils.data.DataLoader, break_after:int):\n",
    "        self.loader = loader\n",
    "        self.break_after = break_after\n",
    "    def __iter__(self):\n",
    "        self.counter = 0\n",
    "        self.iterator = iter(self.loader)\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        image, label = next(self.iterator)\n",
    "        if self.counter >= self.break_after:\n",
    "            raise StopIteration\n",
    "        self.counter += 1\n",
    "        return image, label\n",
    "    def __len__(self):\n",
    "        return min(self.break_after, len(self.loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "087703d7-3f18-4bba-9548-efabcf941c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-07-11 10:42:49 1257509:1257509 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "RLoss: 2.4146196937561037, RPI1000: 0: 100%|██████████████████████████████████████████████| 3/3 [00:04<00:00,  1.38s/it]\n",
      "STAGE:2024-07-11 10:42:55 1257509:1257509 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-07-11 10:42:55 1257509:1257509 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "model = model_incoherent\n",
    "with profile(activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA], record_shapes=True, profile_memory=True, with_stack=True, with_flops=True, with_modules=True, on_trace_ready=torch.profiler.tensorboard_trace_handler(f\"profile.log\")) as prof:\n",
    "    model.train()\n",
    "    history = numpy.zeros((len(dataset.train)))\n",
    "\n",
    "    time_start = time()\n",
    "    running_loss = 0\n",
    "    running_loss_proportion = 0.2\n",
    "    regression = 0\n",
    "\n",
    "    iterator = tqdm(IterationBreaker(dataset.train, 3))\n",
    "\n",
    "    for i, (images, labels) in enumerate(iterator):\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        images = images.to(device, non_blocking=True)\n",
    "\n",
    "        results = model.forward(images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(results, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        history[i] = loss.item()\n",
    "        if running_loss == 0:   running_loss = loss.item()\n",
    "        else:                   running_loss = (1.0 - running_loss_proportion)*running_loss + running_loss_proportion*loss.item()\n",
    "\n",
    "        if time() - time_start >= 10.0 and i >= 3:\n",
    "            time_start = time()\n",
    "            history_slice = history[:i+1]\n",
    "            iteration_slice = numpy.arange(0, i+1)\n",
    "            k, b = numpy.polyfit(iteration_slice, history_slice, 1)\n",
    "            regression = k * 1000\n",
    "        iterator.set_description(f\"RLoss: {running_loss}, RPI1000: {regression}\")\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7407295a-db3b-4998-b0fb-87733a0bd318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorboard in /home/encoder/.local/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /home/encoder/.local/lib/python3.10/site-packages (from tensorboard) (4.25.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/encoder/.local/lib/python3.10/site-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/encoder/.local/lib/python3.10/site-packages (from tensorboard) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/encoder/.local/lib/python3.10/site-packages (from tensorboard) (1.64.1)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/encoder/.local/lib/python3.10/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/encoder/.local/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/encoder/.local/lib/python3.10/site-packages (from tensorboard) (70.2.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/encoder/.local/lib/python3.10/site-packages (from tensorboard) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/encoder/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/encoder/.local/bin/tensorboard\", line 5, in <module>\n",
      "    from tensorboard.main import run_main\n",
      "  File \"/home/encoder/.local/lib/python3.10/site-packages/tensorboard/main.py\", line 27, in <module>\n",
      "    from tensorboard import default\n",
      "  File \"/home/encoder/.local/lib/python3.10/site-packages/tensorboard/default.py\", line 39, in <module>\n",
      "    from tensorboard.plugins.hparams import hparams_plugin\n",
      "  File \"/home/encoder/.local/lib/python3.10/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 30, in <module>\n",
      "    from tensorboard.plugins.hparams import backend_context\n",
      "  File \"/home/encoder/.local/lib/python3.10/site-packages/tensorboard/plugins/hparams/backend_context.py\", line 26, in <module>\n",
      "    from tensorboard.plugins.hparams import metadata\n",
      "  File \"/home/encoder/.local/lib/python3.10/site-packages/tensorboard/plugins/hparams/metadata.py\", line 32, in <module>\n",
      "    NULL_TENSOR = tensor_util.make_tensor_proto(\n",
      "  File \"/home/encoder/.local/lib/python3.10/site-packages/tensorboard/util/tensor_util.py\", line 405, in make_tensor_proto\n",
      "    numpy_dtype = dtypes.as_dtype(nparray.dtype)\n",
      "  File \"/home/encoder/.local/lib/python3.10/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py\", line 677, in as_dtype\n",
      "    if type_value.type == np.string_ or type_value.type == np.unicode_:\n",
      "  File \"/home/encoder/.local/lib/python3.10/site-packages/numpy/__init__.py\", line 397, in __getattr__\n",
      "    raise AttributeError(\n",
      "AttributeError: `np.string_` was removed in the NumPy 2.0 release. Use `np.bytes_` instead.. Did you mean: 'strings'?\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard\n",
    "!tensorboard --logdir=profile.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437443eb-83c3-4cfd-af7e-0621327b7e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
