{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c136c0b0-a514-4cbd-ad50-4a9eb0305507",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4bbfb6c-102b-4769-a954-19002f395ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from belashovplot import TiledPlot\n",
    "from utilities import *\n",
    "from utilities.filters import Gaussian, Window\n",
    "from utilities.training import train, confusion\n",
    "from elements.abstracts import AbstractModulator\n",
    "from elements.modulators import Lens, PhaseModulator, AmplitudeModulator\n",
    "from elements.propagators import FurrierPropagation, ConvolutionalPropagation\n",
    "from elements.composition import CompositeModel, HybridModel\n",
    "from elements.wrappers import CudaMemoryChunker, Incoherent\n",
    "from elements.detectors import ClassificationDetectors, MatrixDetectors\n",
    "from parameters import FigureWidthHeight, FontLibrary\n",
    "from tqdm import tqdm\n",
    "from math import sin, sqrt\n",
    "from pickle import dump, load\n",
    "import torch\n",
    "import numpy\n",
    "import timm\n",
    "import pandas\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4603a3b6-fa6b-40ac-ac03-b63292f5bb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемый девайс: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Используемый девайс:', torch.cuda.get_device_name(device) if torch.cuda.is_available() else 'ЦП')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84eab818-39b4-499a-a6ff-9f0d3478be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(classes:int=10):\n",
    "    return timm.create_model('resnet18', pretrained=False,  in_chans=1, num_classes=classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7625b6b1-196f-4222-8bc2-e9d1d242cbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(cross_entropy_to_mse_proportion:float=1.0):\n",
    "    def loss_function(outputs, targets):\n",
    "        CELoss = torch.nn.functional.cross_entropy(outputs, targets)\n",
    "        MSELoss = torch.nn.functional.mse_loss(torch.nn.functional.softmax(outputs, dim=1), torch.nn.functional.one_hot(targets, num_classes=10).float())\n",
    "        loss = cross_entropy_to_mse_proportion*CELoss + (1.0-cross_entropy_to_mse_proportion)*MSELoss\n",
    "        return loss\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eff8a9e0-e806-42f7-a53b-9c5941de75cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длинна волны:                             500.0 нм\n",
      "Количество вычислительных пикселей:       1336\n",
      "Количество пикселей маски:                334\n",
      "Размер оптических элементов:              10.02 мм\n",
      "Размер пикселя маски:                     30.0 мкм\n",
      "Расстояние между слоями:                  90.52 мм\n",
      "Временная когерентность:                  10.0 нс\n",
      "Время релаксации:                         1.0 мкc\n",
      "Пространственная когерентность:           100.0 мкм\n",
      "Количество усреднений:                    100\n",
      "Размер детекторов:                        167.0 мкм\n",
      "Количество детекторов:                    24 на 24\n",
      "Пропорция CE к MSE лосс:                  0.609798\n",
      "Размер батча:                             50\n",
      "Тип оптимизатора:                         RMSprop\n"
     ]
    }
   ],
   "source": [
    "# Предпочтительные параметры\n",
    "size = 30.0E-6\n",
    "near_N = 1336 #1336\n",
    "near_length = 10.0E-3\n",
    "wavelength = 500.0E-9\n",
    "detectors_amount = 24\n",
    "masks_amount = 3\n",
    "distance = 0.09052\n",
    "\n",
    "# Параметры обучения\n",
    "batch_size = 50\n",
    "learning_rate = 0.009854\n",
    "loss_function_proportion = 0.609798\n",
    "optimizer_type_name = 'RMSprop'\n",
    "optimizer_types_list = {'Adam':torch.optim.Adam, 'SGD':torch.optim.SGD, 'RMSprop':torch.optim.RMSprop, 'Adagrad':torch.optim.Adagrad}\n",
    "\n",
    "# Параметры когерентности\n",
    "spatial_coherence = 100.0E-6\n",
    "time_coherence = 10.0E-9\n",
    "time_relaxation = 1.0E-6\n",
    "mean_samples = 100\n",
    "\n",
    "# Вычисляемые параметры\n",
    "pixels = upper_integer(near_length/size)\n",
    "length = pixels * size\n",
    "cppp = upper_integer(near_N * size / length)\n",
    "N = upper_integer(length*cppp / size) \n",
    "detector_size = length / 60\n",
    "\n",
    "print(f\"Длинна волны:                             {engineering(wavelength, 'м')}\")\n",
    "print(f\"Количество вычислительных пикселей:       {N}\")\n",
    "print(f\"Количество пикселей маски:                {pixels}\")\n",
    "print(f\"Размер оптических элементов:              {engineering(length, 'м')}\")\n",
    "print(f\"Размер пикселя маски:                     {engineering(length/pixels, 'м')}\")\n",
    "print(f\"Расстояние между слоями:                  {engineering(distance, 'м')}\")\n",
    "\n",
    "print(f\"Временная когерентность:                  {engineering(time_coherence, 'с')}\")\n",
    "print(f\"Время релаксации:                         {engineering(time_relaxation, 'c')}\")\n",
    "print(f\"Пространственная когерентность:           {engineering(spatial_coherence, 'м')}\")\n",
    "print(f\"Количество усреднений:                    {mean_samples}\")\n",
    "\n",
    "print(f\"Размер детекторов:                        {engineering(detector_size, 'м')}\")\n",
    "print(f\"Количество детекторов:                    {detectors_amount} на {detectors_amount}\")\n",
    "\n",
    "print(f\"Пропорция CE к MSE лосс:                  {loss_function_proportion}\")\n",
    "print(f\"Размер батча:                             {batch_size}\")\n",
    "print(f\"Тип оптимизатора:                         {optimizer_type_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "302fd5ca-bfbc-4bbe-bd03-22efeb2a3dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f75d96d8430>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral_filter = Window(centers=wavelength, sizes=300.0E-9)\n",
    "detectors_filter = Gaussian((detector_size, detector_size), (0,0))\n",
    "\n",
    "dataset = Dataset('CIFAR10', batch_size, N, N, torch.complex64)\n",
    "dataset.train\n",
    "dataset.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5ffb6620-1dc5-45b6-86c8-295bc3ae458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "propagation         = FurrierPropagation(N, length, wavelength, 1.0, 0.0, distance, 0.4)\n",
    "phase_modulator     = PhaseModulator(N, length, pixels)\n",
    "amplitude_modulator = AmplitudeModulator(N, length, pixels)\n",
    "detectors = MatrixDetectors(N, length, wavelength, detectors_amount, detectors_filter, spectral_filter).to(device)\n",
    "electronic = resnet18()\n",
    "\n",
    "propagation = propagation.to(device)\n",
    "phase_modulator = phase_modulator.to(device)\n",
    "amplitude_modulator = amplitude_modulator.to(device)\n",
    "detectors = detectors.to(device)\n",
    "electronic = electronic.to(device)\n",
    "\n",
    "propagation = torch.nn.DataParallel(propagation)\n",
    "phase_modulator = torch.nn.DataParallel(phase_modulator)\n",
    "amplitude_modulator = torch.nn.DataParallel(amplitude_modulator)\n",
    "detectors = torch.nn.DataParallel(detectors)\n",
    "electronic = torch.nn.DataParallel(electronic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b0d7dce-4227-485c-8be9-01a71ed71abe",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/maindev/.local/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/maindev/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/maindev/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/maindev/OpticalEncoder/elements/abstracts.py\", line 251, in forward\n    field = field * self._multiplier()\nRuntimeError: The size of tensor a (2) must match the size of tensor b (1336) at non-singleton dimension 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m field, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mtrain))\n\u001b[1;32m      2\u001b[0m field \u001b[38;5;241m=\u001b[39m field\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 3\u001b[0m field \u001b[38;5;241m=\u001b[39m \u001b[43mphase_modulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:108\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    106\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 108\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_utils.py:705\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/maindev/.local/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/maindev/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home/maindev/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home/maindev/OpticalEncoder/elements/abstracts.py\", line 251, in forward\n    field = field * self._multiplier()\nRuntimeError: The size of tensor a (2) must match the size of tensor b (1336) at non-singleton dimension 4\n"
     ]
    }
   ],
   "source": [
    "field, _ = next(iter(dataset.train))\n",
    "field = field.to(device)\n",
    "field = phase_modulator(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c239e6-8dad-469d-948e-5df1afa01e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897056b3-2f50-4702-8dc8-0650d2afe509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdef3c1c-3415-405e-b341-f344a02f09d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1088625192642212\n",
      "Loss: 1.1102659702301025\n",
      "Loss: 1.1119208335876465\n",
      "Loss: 1.110910177230835\n",
      "Loss: 1.1119478940963745\n",
      "Loss: 1.1111277341842651\n",
      "Loss: 1.1117554903030396\n",
      "Loss: 1.1104594469070435\n",
      "Loss: 1.110807180404663\n",
      "Loss: 1.1118454933166504\n",
      "Loss: 1.110033631324768\n",
      "Loss: 1.111470103263855\n",
      "Loss: 1.111626386642456\n",
      "Loss: 1.1086947917938232\n",
      "Loss: 1.1129156351089478\n",
      "Loss: 1.1087734699249268\n",
      "Loss: 1.1122708320617676\n",
      "Loss: 1.1119248867034912\n",
      "Loss: 1.1099510192871094\n",
      "Loss: 1.1092486381530762\n",
      "Loss: 1.1098417043685913\n",
      "Loss: 1.1106255054473877\n",
      "Loss: 1.111372947692871\n",
      "Loss: 1.1087270975112915\n",
      "Loss: 1.113295316696167\n",
      "Loss: 1.113590121269226\n",
      "Loss: 1.1090023517608643\n",
      "Loss: 1.1110398769378662\n",
      "Loss: 1.1111435890197754\n",
      "Loss: 1.1094117164611816\n",
      "Loss: 1.1100033521652222\n",
      "Loss: 1.1102880239486694\n",
      "Loss: 1.1113914251327515\n",
      "Loss: 1.109862208366394\n",
      "Loss: 1.1108981370925903\n",
      "Loss: 1.11057710647583\n",
      "Loss: 1.1093593835830688\n",
      "Loss: 1.1105353832244873\n",
      "Loss: 1.1086257696151733\n",
      "Loss: 1.1099516153335571\n",
      "Loss: 1.1120880842208862\n",
      "Loss: 1.1104034185409546\n",
      "Loss: 1.109697937965393\n",
      "Loss: 1.111691951751709\n",
      "Loss: 1.109570026397705\n",
      "Loss: 1.1106947660446167\n",
      "Loss: 1.1097440719604492\n",
      "Loss: 1.111499547958374\n",
      "Loss: 1.1093000173568726\n",
      "Loss: 1.107820987701416\n",
      "Loss: 1.111314058303833\n",
      "Loss: 1.1121132373809814\n",
      "Loss: 1.109499216079712\n",
      "Loss: 1.1117011308670044\n",
      "Loss: 1.1103687286376953\n",
      "Loss: 1.1122734546661377\n",
      "Loss: 1.1112403869628906\n",
      "Loss: 1.111594796180725\n",
      "Loss: 1.1113628149032593\n",
      "Loss: 1.11148202419281\n",
      "Loss: 1.1105831861495972\n",
      "Loss: 1.1106336116790771\n",
      "Loss: 1.1088268756866455\n",
      "Loss: 1.1093393564224243\n",
      "Loss: 1.1099835634231567\n",
      "Loss: 1.1112077236175537\n",
      "Loss: 1.1110858917236328\n",
      "Loss: 1.1092841625213623\n",
      "Loss: 1.1104276180267334\n",
      "Loss: 1.110120415687561\n",
      "Loss: 1.11067795753479\n",
      "Loss: 1.1103993654251099\n",
      "Loss: 1.1111977100372314\n",
      "Loss: 1.1109070777893066\n",
      "Loss: 1.111476182937622\n",
      "Loss: 1.1082146167755127\n",
      "Loss: 1.1110033988952637\n",
      "Loss: 1.1118630170822144\n",
      "Loss: 1.1099846363067627\n",
      "Loss: 1.1101113557815552\n",
      "Loss: 1.1093569993972778\n",
      "Loss: 1.109808325767517\n",
      "Loss: 1.110507845878601\n",
      "Loss: 1.1111153364181519\n",
      "Loss: 1.1098982095718384\n",
      "Loss: 1.1102319955825806\n",
      "Loss: 1.1100965738296509\n",
      "Loss: 1.1098053455352783\n",
      "Loss: 1.1088027954101562\n",
      "Loss: 1.1112648248672485\n",
      "Loss: 1.1107826232910156\n",
      "Loss: 1.1108149290084839\n",
      "Loss: 1.1088536977767944\n",
      "Loss: 1.11040198802948\n",
      "Loss: 1.1101781129837036\n",
      "Loss: 1.1112958192825317\n",
      "Loss: 1.111088514328003\n",
      "Loss: 1.1105504035949707\n",
      "Loss: 1.1080721616744995\n",
      "Loss: 1.107143521308899\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Определение моделей\n",
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.layer = nn.Linear(10000, 20000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "        self.layer = nn.Linear(20000, 30000)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "# Инициализация моделей\n",
    "model1 = Model1()\n",
    "model2 = Model2()\n",
    "\n",
    "# Перемещение моделей на доступные GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model1 = model1.to(device)\n",
    "model2 = model2.to(device)\n",
    "\n",
    "# Использование DataParallel для автоматического распределения по GPU\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model1 = nn.DataParallel(model1)\n",
    "    model2 = nn.DataParallel(model2)\n",
    "\n",
    "for i in range(100):\n",
    "    # Пример данных\n",
    "    data = torch.randn(64, 10000).to(device)  # Батч размером 64, каждый с вектором размером 10\n",
    "    \n",
    "    # Оптимизация и критерий потерь\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(list(model1.parameters()) + list(model2.parameters()), lr=0.01)\n",
    "    \n",
    "    # Обработка данных первой моделью\n",
    "    output1 = model1(data)\n",
    "    \n",
    "    # Обработка данных второй моделью\n",
    "    output2 = model2(output1)\n",
    "    \n",
    "    # Пример цели\n",
    "    target = torch.randn(64, 30000).to(device)\n",
    "    loss = criterion(output2, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59e43e-132c-4324-ba96-5d21dc8ba16c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
