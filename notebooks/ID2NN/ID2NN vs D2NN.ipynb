{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87498b68-2db5-4821-9608-69d5bdada34e",
   "metadata": {
    "id": "ccc45c47-db3b-4054-9d55-fe9d135dc729",
    "tags": []
   },
   "source": [
    "# Настройка среды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb08733f-d647-4841-baf1-21705ed7c72e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb08733f-d647-4841-baf1-21705ed7c72e",
    "outputId": "68907ff5-6494-4d13-f4d1-796b0d66d334",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ca8b6c-9f4c-4fd6-8470-23349fb2e246",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Импорты и настройка модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5469f1f-b85d-48c1-b187-0ff762d1ec62",
   "metadata": {
    "id": "d1193e17-e375-41a3-8f98-9bea9bfd4d70",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from belashovplot import TiledPlot\n",
    "from utilities import *\n",
    "from utilities.filters import Gaussian, Window\n",
    "from utilities.training import train, confusion\n",
    "from elements.abstracts import AbstractModulator\n",
    "from elements.modulators import Lens, PhaseModulator, AmplitudeModulator\n",
    "from elements.propagators import FurrierPropagation, ConvolutionalPropagation\n",
    "from elements.composition import CompositeModel, HybridModel\n",
    "from elements.wrappers import CudaMemoryChunker, Incoherent\n",
    "from elements.detectors import ClassificationDetectors, MatrixDetectors\n",
    "from parameters import FigureWidthHeight, FontLibrary\n",
    "from tqdm import tqdm\n",
    "from math import sin, sqrt\n",
    "from pickle import dump, load\n",
    "import torch\n",
    "import numpy\n",
    "import timm\n",
    "import pandas\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee496b5-4fb4-4558-82e1-96c3c466616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2c2aba-6201-421c-a8e0-62cae4775ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FontLibrary.Fonts.PlotTitle.FontSize = 16\n",
    "\n",
    "FontLibrary.Fonts.DescriptionLeft.FontSize = 12\n",
    "FontLibrary.Fonts.DescriptionLeft.FontWeight = 'bold'\n",
    "FontLibrary.Fonts.DescriptionLeft.FontStyle = 'italic'\n",
    "\n",
    "FontLibrary.Fonts.DescriptionBottom.FontSize = 10\n",
    "FontLibrary.Fonts.DescriptionBottom.FontWeight = 'bold'\n",
    "FontLibrary.Fonts.DescriptionBottom.FontStyle = 'italic'\n",
    "\n",
    "FontLibrary.Fonts.DescriptionTop.FontSize = 10\n",
    "FontLibrary.Fonts.DescriptionTop.FontWeight = 'bold'\n",
    "FontLibrary.Fonts.DescriptionTop.FontStyle = 'italic'\n",
    "\n",
    "FontLibrary.Fonts.ColumnDescriptionTop.FontSize = 9\n",
    "FontLibrary.Fonts.ColumnDescriptionBottom.FontSize = 9\n",
    "FontLibrary.Fonts.RowDescriptionLeft.FontSize = 9\n",
    "FontLibrary.Fonts.RowDescriptionRight.FontSize = 9\n",
    "FontLibrary.Fonts.AxisX.FontSize = 8\n",
    "FontLibrary.Fonts.AxisY.FontSize = 8\n",
    "FigureWidthHeight = (6.69291, 10.1181-1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d779f5ed-d388-404b-b724-6940850511aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемый девайс: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Используемый девайс:', torch.cuda.get_device_name(device) if torch.cuda.is_available() else 'ЦП')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d9937-3449-4086-bbf1-ae8702b9491a",
   "metadata": {},
   "source": [
    "# Определение параметров и сопутствующих методов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84eab818-39b4-499a-a6ff-9f0d3478be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(classes:int=10):\n",
    "    return timm.create_model('resnet18', pretrained=False,  in_chans=1, num_classes=classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecacd19a-d106-4922-858a-ecdbc54fa33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(cross_entropy_to_mse_proportion:float=1.0):\n",
    "    def loss_function(outputs, targets):\n",
    "        CELoss = torch.nn.functional.cross_entropy(outputs, targets)\n",
    "        MSELoss = torch.nn.functional.mse_loss(torch.nn.functional.softmax(outputs, dim=1), torch.nn.functional.one_hot(targets, num_classes=10).float())\n",
    "        loss = cross_entropy_to_mse_proportion*CELoss + (1.0-cross_entropy_to_mse_proportion)*MSELoss\n",
    "        return loss\n",
    "    return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b7c20d6-5807-4943-85c1-ecbf3f0c97ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длинна волны:                             500.0 нм\n",
      "Количество вычислительных пикселей:       1336\n",
      "Количество пикселей маски:                334\n",
      "Размер оптических элементов:              10.02 мм\n",
      "Размер пикселя маски:                     30.0 мкм\n",
      "Расстояние между слоями:                  90.52 мм\n",
      "Временная когерентность:                  10.0 нс\n",
      "Время релаксации:                         1.0 мкc\n",
      "Пространственная когерентность:           100.0 мкм\n",
      "Количество усреднений:                    300\n",
      "Размер детекторов:                        167.0 мкм\n",
      "Количество детекторов:                    24 на 24\n",
      "Пропорция CE к MSE лосс:                  0.609798\n",
      "Размер батча:                             128\n",
      "Тип оптимизатора:                         RMSprop\n"
     ]
    }
   ],
   "source": [
    "# Предпочтительные параметры\n",
    "size = 30.0E-6\n",
    "near_N = 1336 #1336\n",
    "near_length = 10.0E-3\n",
    "wavelength = 500.0E-9\n",
    "detectors_amount = 24\n",
    "masks_amount = 3\n",
    "distance = 0.09052\n",
    "\n",
    "# Параметры обучения\n",
    "batch_size = 128\n",
    "learning_rate = 0.009854\n",
    "loss_function_proportion = 0.609798\n",
    "optimizer_type_name = 'RMSprop'\n",
    "optimizer_types_list = {'Adam':torch.optim.Adam, 'SGD':torch.optim.SGD, 'RMSprop':torch.optim.RMSprop, 'Adagrad':torch.optim.Adagrad}\n",
    "\n",
    "# Параметры когерентности\n",
    "spatial_coherence = 100.0E-6\n",
    "time_coherence = 10.0E-9\n",
    "time_relaxation = 1.0E-6\n",
    "mean_samples = 300\n",
    "\n",
    "# Вычисляемые параметры\n",
    "pixels = upper_integer(near_length/size)\n",
    "length = pixels * size\n",
    "cppp = upper_integer(near_N * size / length)\n",
    "N = upper_integer(length*cppp / size) \n",
    "detector_size = length / 60\n",
    "\n",
    "print(f\"Длинна волны:                             {engineering(wavelength, 'м')}\")\n",
    "print(f\"Количество вычислительных пикселей:       {N}\")\n",
    "print(f\"Количество пикселей маски:                {pixels}\")\n",
    "print(f\"Размер оптических элементов:              {engineering(length, 'м')}\")\n",
    "print(f\"Размер пикселя маски:                     {engineering(length/pixels, 'м')}\")\n",
    "print(f\"Расстояние между слоями:                  {engineering(distance, 'м')}\")\n",
    "\n",
    "print(f\"Временная когерентность:                  {engineering(time_coherence, 'с')}\")\n",
    "print(f\"Время релаксации:                         {engineering(time_relaxation, 'c')}\")\n",
    "print(f\"Пространственная когерентность:           {engineering(spatial_coherence, 'м')}\")\n",
    "print(f\"Количество усреднений:                    {mean_samples}\")\n",
    "\n",
    "print(f\"Размер детекторов:                        {engineering(detector_size, 'м')}\")\n",
    "print(f\"Количество детекторов:                    {detectors_amount} на {detectors_amount}\")\n",
    "\n",
    "print(f\"Пропорция CE к MSE лосс:                  {loss_function_proportion}\")\n",
    "print(f\"Размер батча:                             {batch_size}\")\n",
    "print(f\"Тип оптимизатора:                         {optimizer_type_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78af8b-d5de-4dcd-b889-f96d6608582f",
   "metadata": {},
   "source": [
    "# Инициализация моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9329a7af-385c-4d20-aad5-7a9af78c3e73",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataParallel' object has no attribute 'attach_forward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m optical_incoherent \u001b[38;5;241m=\u001b[39m CompositeModel(\u001b[38;5;241m*\u001b[39melements)\n\u001b[1;32m     25\u001b[0m optical_coherent \u001b[38;5;241m=\u001b[39m deepcopy(optical_incoherent)\n\u001b[0;32m---> 26\u001b[0m \u001b[43moptical_incoherent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mincoherent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Гибридные модели\u001b[39;00m\n\u001b[1;32m     29\u001b[0m hybrid_model_incoherent \u001b[38;5;241m=\u001b[39m HybridModel(optical_incoherent, detectors_incoherent, electronic_incoherent)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/OpticalEncoder/elements/composition.py:47\u001b[0m, in \u001b[0;36mCompositeModel.wrap\u001b[0;34m(self, wrapper)\u001b[0m\n\u001b[1;32m     45\u001b[0m wrapper \u001b[38;5;241m=\u001b[39m wrapper\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrappers:\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mwrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattach_forward\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrappers \u001b[38;5;241m=\u001b[39m [wrapper]\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataParallel' object has no attribute 'attach_forward'"
     ]
    }
   ],
   "source": [
    "# Модуль некогерентности\n",
    "incoherent = Incoherent(spatial_coherence, time_coherence, time_relaxation, mean_samples, N, length).to(device)\n",
    "\n",
    "# Модули детекторов\n",
    "spectral_filter = Window(centers=wavelength, sizes=300.0E-9)\n",
    "detectors_filter = Gaussian((detector_size, detector_size), (0,0))\n",
    "detectors_incoherent = MatrixDetectors(N, length, wavelength, detectors_amount, detectors_filter, spectral_filter).to(device)\n",
    "detectors_coherent = deepcopy(detectors_incoherent)\n",
    "\n",
    "# Электронные модели\n",
    "electronic_incoherent = resnet18()\n",
    "electronic_coherent = deepcopy(electronic_incoherent)\n",
    "\n",
    "# Оптические модели\n",
    "propagation = FurrierPropagation(N, length, wavelength, 1.0, 0.0, distance, 0.4)\n",
    "phase_modulators = [PhaseModulator(N, length, pixels) for i in range(masks_amount)]\n",
    "amplitude_modulators = [AmplitudeModulator(N, length, pixels) for i in range(masks_amount)]\n",
    "elements = [phase_modulators[0], amplitude_modulators[0]]\n",
    "for phase_modulator, amplitude_modulator in zip(phase_modulators[1:], amplitude_modulators[1:]):\n",
    "    elements.append(propagation)\n",
    "    elements.append(phase_modulator)\n",
    "    elements.append(amplitude_modulator)\n",
    "elements.append(propagation)\n",
    "optical_incoherent = CompositeModel(*elements)\n",
    "optical_coherent = deepcopy(optical_incoherent)\n",
    "optical_incoherent.wrap(torch.nn.DataParallel(incoherent))\n",
    "\n",
    "# Гибридные модели\n",
    "hybrid_model_incoherent = HybridModel(optical_incoherent, detectors_incoherent, electronic_incoherent).to(device)\n",
    "hybrid_model_coherent = HybridModel(optical_coherent, detectors_coherent, electronic_coherent).to(device)\n",
    "\n",
    "# Распределённые модели\n",
    "model_incoherent = torch.nn.DataParallel(hybrid_model_incoherent)\n",
    "model_coherent = torch.nn.DataParallel(hybrid_model_coherent)\n",
    "\n",
    "# Набор данных\n",
    "dataset = Dataset('CIFAR10', batch_size, N, N, torch.complex64)\n",
    "dataset.train\n",
    "dataset.test\n",
    "\n",
    "# Тип оптимизатора и лосс-функция\n",
    "loss_function = combined_loss(loss_function_proportion)\n",
    "optimizer_type = optimizer_types_list[optimizer_type_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b62f4-034b-474a-a3bb-19562cc61b62",
   "metadata": {},
   "source": [
    "# Обучение некогерентной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3fb9fdb-9dd2-4dd3-85a4-417dbbdb55d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_histories_incoherent = []\n",
    "cofusion_matrixes_incoherent = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a595b959-5f73-4ec5-bbd4-8ffdae460bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/79 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optimizer_type(model_incoherent\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[0;32m----> 2\u001b[0m cofusion_matrixes_incoherent\u001b[38;5;241m.\u001b[39mappend(\u001b[43mconfusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_incoherent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mТочность: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39mnumpy\u001b[38;5;241m.\u001b[39msum(numpy\u001b[38;5;241m.\u001b[39mdiagonal(cofusion_matrixes_incoherent[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m/\u001b[39mnumpy\u001b[38;5;241m.\u001b[39msum(cofusion_matrixes_incoherent[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n",
      "File \u001b[0;32m~/OpticalEncoder/utilities/training.py:58\u001b[0m, in \u001b[0;36mconfusion\u001b[0;34m(model, dataset, classes)\u001b[0m\n\u001b[1;32m     56\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     57\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 58\u001b[0m values, indexes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(labels, indexes):\n\u001b[1;32m     60\u001b[0m     matrix[label\u001b[38;5;241m.\u001b[39mitem(), index\u001b[38;5;241m.\u001b[39mitem()] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:171\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mbuffers()):\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_device_obj:\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule must have its parameters and buffers \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m                            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon device \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_device_obj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (device_ids[0]) but found one of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m                            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem on device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    175\u001b[0m inputs, module_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscatter(inputs, kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# for forward function without any inputs, empty list and dict will be created\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# so the module can be executed on one device which is the first one in device_ids\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:3"
     ]
    }
   ],
   "source": [
    "optimizer = optimizer_type(model_incoherent.parameters(), lr=learning_rate)\n",
    "cofusion_matrixes_incoherent.append(confusion(model_incoherent, dataset))\n",
    "print(f\"Точность: {100*numpy.sum(numpy.diagonal(cofusion_matrixes_incoherent[-1], 0))/numpy.sum(cofusion_matrixes_incoherent[-1])}%\")\n",
    "for i in range(10):\n",
    "    loss_histories_incoherent.append(train(model_incoherent, dataset, optimizer, loss_function))\n",
    "    cofusion_matrixes_incoherent.append(confusion(model_incoherent, dataset))\n",
    "    print(f\"Точность: {100*numpy.sum(numpy.diagonal(cofusion_matrixes_incoherent[-1], 0))/numpy.sum(cofusion_matrixes_incoherent[-1])}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424ebbe-13b5-4c91-8ed6-52052757fcf8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Обучение когерентной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00739b3-b362-4393-8a0a-30da73af2c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_histories_coherent = []\n",
    "cofusion_matrixes_coherent = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be41c89-4209-45d7-8343-596f646a66b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizer_type(model_coherent.parameters(), lr=learning_rate)\n",
    "cofusion_matrixes_coherent.append(confusion(model_coherent, dataset))\n",
    "print(f\"Точность: {100*numpy.sum(numpy.diagonal(cofusion_matrixes_coherent[-1], 0))/numpy.sum(cofusion_matrixes_coherent[-1])}%\")\n",
    "for i in range(10):\n",
    "    loss_histories_coherent.append(train(model_coherent, dataset, optimizer, loss_function))\n",
    "    cofusion_matrixes_coherent.append(confusion(model_coherent, dataset))\n",
    "    print(f\"Точность: {100*numpy.sum(numpy.diagonal(cofusion_matrixes_coherent[-1], 0))/numpy.sum(cofusion_matrixes_coherent[-1])}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
